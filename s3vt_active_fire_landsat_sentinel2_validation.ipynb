{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3VT Landsat and Sentinel 2 validation of hotspots - working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook demonstrates how to:\n",
    " \n",
    "From a candidate latitude longitude and solar_day:\n",
    "* determine if intersecting Landsat or Sentinel 2 ARD exists\n",
    "* apply the platform specific tests to determine if hotspots were detected in the vicinity 5km of hotspot\n",
    "* return number of pixel identified as hotspots\n",
    "* save a boolean file labelled with solar date of acquisition\n",
    "* as a secondary test perform a Normalized Burnt Ratio and return as a binary with solar date of acquisition\n",
    "    * find canidate dates within a time range of source hotspot\n",
    "        * find closest before date within tolerance (dNBR A)\n",
    "        * find closest after date within tolerance (dNBR B)\n",
    "        * candidate closest to source hotspot will be used for hotspot matching i.e. high resolution hotspot\n",
    "\n",
    "Assumptions:\n",
    "* reflectance values are scaled by 10000 i.e. 100% reflectance = 10000\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datacube\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import xarray as xr\n",
    "\n",
    "sys.path.append(\"Scripts\")\n",
    "from dea_datahandling import load_ard\n",
    "from dea_plotting import rgb\n",
    "from dea_bandindices import calculate_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='validating_hotspots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buffer candidate hotspot with 5 kilometre radius (or .05 degrees will do)\n",
    "def buffer_hotspot(lon, lat):\n",
    "    ul_lon = lon - 0.05\n",
    "    lr_lon = lon + 0.05\n",
    "    ul_lat = lat + 0.05\n",
    "    lr_lat = lat - 0.05\n",
    "    return ((ul_lon, lr_lon), (ul_lat, lr_lat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be ignorant of the sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure sensor bands - #TODO implement sensor ignorance code here\n",
    "sensor_ignorance = {'msi':{'0.433-0.453': 'nbar_coastal_aerosol',\n",
    "                           '0.450-0.515': 'nbar_blue',\n",
    "                           '0.525-0.600': 'nbar_green',\n",
    "                           '0.630-0.680': 'nbar_red',\n",
    "                           '0.845-0.885': 'nbar_nir_1',\n",
    "                           '1.560-1.660': 'nbar_swir_2',\n",
    "                           '2.100-2.300': 'nbar_swir_3'},\n",
    "                   'oli': {'0.433-0.453': 'nbart_band01',\n",
    "                           '0.450-0.515': 'nbart_band02',\n",
    "                           '0.525-0.600': 'nbart_band03',\n",
    "                           '0.630-0.680': 'nbart_band04',\n",
    "                           '0.845-0.885': 'nbart_band05',\n",
    "                           '1.560-1.660': 'nbart_band06',\n",
    "                           '2.100-2.300': 'nbart_band07'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments\n",
    "hotspot_lon = 147.92 #149.93 #150.8\n",
    "hotspot_lat = -37.48 #-34.08 #-32.65\n",
    "hotspot_solar_day = \"2019-12-16\",\"2019-12-22\" #\"2019-12-14\",\"2019-12-20\" #\"2019-12-31\"#, \"2020-06-10\" #, '2020-01-20'\n",
    "sensors_products = {'oli': ['ga_ls8c_ard_3'], 'msi': ['ga_s2a_ard_nbar_granule', 'ga_s2b_ard_nbar_granule']}\n",
    "xtuple, ytuple = buffer_hotspot(hotspot_lon, hotspot_lat)\n",
    "sensor = 'msi'\n",
    "measurements = []\n",
    "for measurement in sensor_ignorance[sensor]:\n",
    "    measurements.append(sensor_ignorance[sensor][measurement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measurement_list(ds, product):\n",
    "    measurement_list = []\n",
    "    for i in dc.list_products().name:\n",
    "        for j in dc.list_measurements().query('product == @i').name:\n",
    "            if i == product:\n",
    "                measurement_list.append([i, '--',j])\n",
    "    return(measurement_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# potentially unambiguous active fire pixels\n",
    "def get_candidates(ds):\n",
    "    test1 = (((ds[sensor_ignorance[sensor]['2.100-2.300']] / ds[sensor_ignorance[sensor]['0.845-0.885']]) > 2.5) *\n",
    "             ((ds[sensor_ignorance[sensor]['2.100-2.300']]  - ds[sensor_ignorance[sensor]['0.845-0.885']]) > 3000) *\n",
    "             (ds[sensor_ignorance[sensor]['2.100-2.300']] > 5000))\n",
    "    # Unambiguous fire pixels\n",
    "    test2 = (((ds[sensor_ignorance[sensor]['1.560-1.660']] > 8000) *\n",
    "              (ds[sensor_ignorance[sensor]['0.433-0.453']] < 2000)) *\n",
    "             ((ds[sensor_ignorance[sensor]['0.845-0.885']] > 4000) +\n",
    "              (ds[sensor_ignorance[sensor]['2.100-2.300']] < 1000)).clip(min=0, max=1))\n",
    "    # other candidate fire pixels\n",
    "    test3 = (((ds[sensor_ignorance[sensor]['2.100-2.300']]/ds[sensor_ignorance[sensor]['0.845-0.885']]) > 1.8)*\n",
    "             (ds[sensor_ignorance[sensor]['2.100-2.300']]-ds[sensor_ignorance[sensor]['0.845-0.885']]  > 1700))\n",
    "    unambiguous = (test1 + test2 + test3).clip(min=0, max=1)\n",
    "    return(unambiguous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_kernel_array(y, x, array):\n",
    "    \n",
    "    T, Y, X = array.shape\n",
    "\n",
    "    ymin = y - 60\n",
    "    ymax = y + 60\n",
    "    xmin = x - 60\n",
    "    xmax = x + 60\n",
    "    \n",
    "    if ymin < 0:\n",
    "        ymin = 0\n",
    "    \n",
    "    if xmin < 0:\n",
    "        xmin = 0\n",
    "\n",
    "    if ymax > Y:\n",
    "        ymax = Y\n",
    "        \n",
    "    if xmax > X:\n",
    "        xmax = X\n",
    "\n",
    "    try:\n",
    "        outarray = array[0][:, ymin:ymax][xmin:xmax]\n",
    "    except:\n",
    "        outarray = np.nans((61,61), dtype=np.float64)\n",
    "    \n",
    "    return(outarray, (ymin, ymax, xmin, xmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test6(ds):\n",
    "    #6. ratio b7 b6 > 1.6\n",
    "    return((ds[sensor_ignorance[sensor]['2.100-2.300']]/ds[sensor_ignorance[sensor]['1.560-1.660']]) > 1.6 )         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oceans test\n",
    "#7. {b4 > b5 AND b5 > b6 AND b6 > b7 AND b1 - b7 < 0.2}\n",
    "def run_test7(ds):\n",
    "    test7 = ((ds[sensor_ignorance[sensor]['0.630-0.680']]>ds[sensor_ignorance[sensor]['0.845-0.885']])*\n",
    "             (ds[sensor_ignorance[sensor]['0.845-0.885']]>ds[sensor_ignorance[sensor]['1.560-1.660']])*\n",
    "             (ds[sensor_ignorance[sensor]['1.560-1.660']]>ds[sensor_ignorance[sensor]['2.100-2.300']])*\n",
    "             ((ds[sensor_ignorance[sensor]['0.433-0.453']]-ds[sensor_ignorance[sensor]['2.100-2.300']]) < 2000))\n",
    "\n",
    "    return(test7.clip(min=0, max=1))#.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Water bodies test - comment - seems like  bad test / smoke complications?\n",
    "#AND\n",
    "#8. {(b3 > b2)\n",
    "def run_test8(ds):    \n",
    "    test8 = (ds[sensor_ignorance[sensor]['0.525-0.600']]>ds[sensor_ignorance[sensor]['0.450-0.515']])\n",
    "\n",
    "    return(test8.clip(min=0, max=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#OR\n",
    "#9. (b1 > b2 AND b2 > b3 AND b3 < b4)}.\n",
    "\n",
    "def run_test9(ds):\n",
    "    test9 = ((ds[sensor_ignorance[sensor]['0.433-0.453']]>ds[sensor_ignorance[sensor]['0.450-0.515']]) *\n",
    "            (ds[sensor_ignorance[sensor]['0.450-0.515']]>ds[sensor_ignorance[sensor]['0.525-0.600']])*\n",
    "            (ds[sensor_ignorance[sensor]['0.525-0.600']]<ds[sensor_ignorance[sensor]['0.630-0.680']]))\n",
    "  \n",
    "    return(test9.clip(min=0, max=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_watermasks(ds):\n",
    "    watermask=(run_test7(ds)+run_test8(ds)+run_test9(ds)).clip(min=0, max=1)\n",
    "    return(watermask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hotspots(ds):\n",
    "    # Find the candidates and perform context check\n",
    "    # TODO create mask that is ref7 > 0, non water and not other candidates\n",
    "    # mask\n",
    "    # b7=<0\n",
    "    # water\n",
    "    # othercandidates\n",
    "    #candidates = (test1 + test2 + test3).clip(min=0, max=1)\n",
    "    candidates = get_candidates(ds)\n",
    "    watermasks = get_watermasks(ds)\n",
    "    indices = np.where(candidates.data == 1)\n",
    "    swircandidates = (ds[sensor_ignorance[sensor]['2.100-2.300']].where(candidates.data == 0)).where(watermasks.data == 0)\n",
    "    nircandidates = (ds[sensor_ignorance[sensor]['0.845-0.885']].where(candidates.data == 0)).where(watermasks.data == 0)\n",
    "\n",
    "    test4 = (candidates*0)\n",
    "    test5 = (candidates*0)\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    while index < len(indices[1]):\n",
    "        y = indices[1][index]\n",
    "        x = indices[2][index]\n",
    "\n",
    "        #4. ratio between b7 b5 > ratio b7 b5 + max[3x std ratio b7 and b5, 0.8 ]\n",
    "        #AND\n",
    "        #5. b7 > b7 + max[3x std b7, 0.08]\n",
    "        #AND\n",
    "\n",
    "        #swirkernel = get_context_kernel_array(y,x,ds[sensor_ignorance[sensor]['2.100-2.300']].data)[0]\n",
    "        #nirkernel = get_context_kernel_array(y,x,ds[sensor_ignorance[sensor]['0.845-0.885']].data)[0]\n",
    "        swirkernel = get_context_kernel_array(y,x,swircandidates.data)[0]\n",
    "        nirkernel = get_context_kernel_array(y,x,nircandidates.data)[0] \n",
    "\n",
    "        swir = ds[sensor_ignorance[sensor]['2.100-2.300']].data[0][y][x]\n",
    "        nir = ds[sensor_ignorance[sensor]['0.845-0.885']].data[0][y][x]\n",
    "\n",
    "        test4.data[0][y][x] = ((swir/nir) > (np.nanmean(swirkernel/nirkernel) + max(3*np.nanstd(swirkernel/nirkernel), 0.8))) \n",
    "        test5.data[0][y][x] = (swir > (np.nanmean(swirkernel) + max(3*np.nanstd(swirkernel), 0.08)))\n",
    "\n",
    "        #print(test4.data[0][y][x],(swir/nir), (np.nanmean(swirkernel/nirkernel) + max(3*np.nanstd(swirkernel/nirkernel), 0.8)))\n",
    "        #print(test5.data[0][y][x], swir,(np.nanmean(swirkernel) + max(3*np.nanstd(swirkernel), 0.08)) )\n",
    "        # Write values to new dimension\n",
    "        #print(index, y, x, get_context_kernel_array(y,x,ds[sensor_ignorance[sensor]['2.100-2.300']].data)[1])\n",
    "        index = index + 1\n",
    "    test6 = run_test6(ds)\n",
    "    hotspots = len(np.where((candidates*(test4*test5*test6)).data == 1))\n",
    "    return(hotspots, (candidates*(test4*test5*test6)))\n",
    "#(candidates*(test4*test5*test6)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nbr(ds):\n",
    "    swir = ds[sensor_ignorance[sensor]['2.100-2.300']]\n",
    "    nir = ds[sensor_ignorance[sensor]['1.560-1.660']]\n",
    "    return((nir - swir) / (swir + nir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_measurement_list(ds,'ga_s2a_ard_nbar_granule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    'x': xtuple, \n",
    "    'y': ytuple,\n",
    "    'time': (hotspot_solar_day),\n",
    "    'measurements': measurements,\n",
    "    'output_crs': 'EPSG:3577',\n",
    "    'resolution': (-30, 30),\n",
    "    #'group_by': 'solar_day'\n",
    "}\n",
    "\n",
    "# Load available data from Landsat 8 and filter to retain only times\n",
    "# with at least 99% good data\n",
    "print(sensors_products[sensor], query)\n",
    "try:\n",
    "    ds = load_ard(dc=dc, products=sensors_products[sensor], min_gooddata=0.99, **query)\n",
    "    #ds = dc.load(products=sensors_products[sensor], **query)\n",
    "    rgb(ds, bands=[sensor_ignorance[sensor]['2.100-2.300'],sensor_ignorance[sensor]['0.845-0.885'],sensor_ignorance[sensor]['0.450-0.515']], index=0)\n",
    "except:\n",
    "    result = '-'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotspots, hotspot_array = get_hotspots(ds)\n",
    "print(\"This many hotspots have been detected -\", hotspots)\n",
    "hotspot_array.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbar1 = nbr(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbbr2 = get_nbr(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((nbbr2[0]-nbar1[0])<-0.09).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "import xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ((nbbr2[0]-nbar1[0])<-0.09)\n",
    "#ndimage.binary_dilation(a).astype(a.dtype).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = (a*0).where(ndimage.binary_dilation(a))\n",
    "#c = (b*0).where(ndimage.binary_dilation(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = (a*1).where(ndimage.binary_erosion(dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://wiki.landscapetoolbox.org/doku.php/remote_sensing_methods:normalized_burn_ratio\n",
    "\n",
    "ΔNBR = NBR prefire - NBR postfire\n",
    "\n",
    "ΔNBR Burn Severity Categories\n",
    "\n",
    "ΔNBR\tBurn Severity\n",
    "* < -0.25         High post-fire regrowth\n",
    "* -0.25 to -0.1\t  Low post-fire regrowth\n",
    "* -0.1 to +0.1\t  Unburned\n",
    "* 0.1 to 0.27\t  Low-severity burn\n",
    "* 0.27 to 0.44\t  Moderate-low severity burn\n",
    "* 0.44 to 0.66\t  Moderate-high severity burn\n",
    "* '> 0.66\t      High-severity burn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest(items, pivot):\n",
    "    return min(items, key=lambda x: abs(x - pivot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest([datetime(2020,1,1), datetime(2020,1,6), datetime(2020,1,12)], datetime(2020,1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "451432e065124f0787b3e7a25e3e0d41": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletZoomControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "zoom_in_text",
        "zoom_in_title",
        "zoom_out_text",
        "zoom_out_title"
       ]
      }
     },
     "a8eff2e4864346ca8959cb79bdf3f9ab": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletAttributionControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "prefix"
       ],
       "position": "bottomright",
       "prefix": "Leaflet"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
