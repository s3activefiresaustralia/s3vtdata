{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftplib\n",
    "from pathlib import Path\n",
    "import io\n",
    "import boto3\n",
    "from netCDF4 import Dataset\n",
    "import datetime as dt\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "import xmltodict\n",
    "import yaml\n",
    "import argparse\n",
    "import os\n",
    "import subprocess\n",
    "import logging \n",
    "logger = logging.getLogger()\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(level=logging.INFO)\n",
    "logging.basicConfig(filename='notebook_data_management.log',level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ftp_file_list(username, password, url, directory):\n",
    "    ftp = ftplib.FTP(url)\n",
    "    ftp.login(username, password)\n",
    "    ftp.pwd()\n",
    "    ftp.cwd(directory)\n",
    "    return(ftp.nlst())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ftp_dir(username, password, url, directory, subdirectory):\n",
    "    directory = os.path.join(directory, subdirectory)\n",
    "    url = os.path.join('ftp://', url)\n",
    "    url.split()\n",
    "    target_path = str(os.path.join(url, directory))\n",
    "    # TODO - use depth of folder structure to determine --cut-dirs number\n",
    "    try:\n",
    "        subprocess.call(['wget', '--user='+username, '--password='+password, '--recursive', target_path, '-nH', '--cut-dirs=2', '--directory-prefix='+subdirectory])\n",
    "        logger.info(str(['wget', '--user='+username, '--password='+password, '--resursive', target_path, '-nH', '--cut-dirs=2', '--directory-prefix='+subdirectory]))\n",
    "        success = True\n",
    "    except:\n",
    "        logger.info(\"Remote file retrieval failed \"+str(['wget', '--user='+username, '--password='+password, target_path]))\n",
    "        success = False\n",
    "    return(success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polygon_from_gml(gml_dict):\n",
    "    listoftuples = []\n",
    "    for i in list(gml_dict.split(\" \")):\n",
    "        pair = (float(i.split(',')[1]), float(i.split(',')[0]))\n",
    "        listoftuples.append(pair)\n",
    "    return(listoftuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPF_FRP_read(filename):\n",
    "    print (\"Processing \",filename)\n",
    "    try:\n",
    "        dataset = Dataset(filename)\n",
    "    except (RuntimeError):\n",
    "        print (\"Unable to open \",filename)\n",
    "        sys.exit(1)\n",
    "    IPF_FRP =  gpd.GeoDataFrame()\n",
    "    for var in dataset.variables:\n",
    "        # print (var)\n",
    "        temp = dataset[var]\n",
    "        if len(temp.shape) < 2:\n",
    "            IPF_FRP[var] = dataset[var][:]\n",
    "    IPF_FRP.geometry = gpd.points_from_xy(IPF_FRP.longitude, IPF_FRP.latitude)\n",
    "    return IPF_FRP    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as config:\n",
    "    cfg = yaml.load(config, Loader=yaml.Loader)    \n",
    "    \n",
    "    for configuration in cfg['configurations']:\n",
    "        configuration = configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get File List from server\n",
    "# Run this if no local inventory exists - delete to refresh\n",
    "\n",
    "if not os.path.exists('s3mpc_inventory.txt'):\n",
    "\n",
    "    # Determine number of records to retrieve\n",
    "    sen3 = get_ftp_file_list(configuration['ftpusername'], configuration['ftppassword'], configuration['ftpurl'], configuration['ftpdirectory']) \n",
    "    with open('s3mpc_inventory.txt', 'w') as outfile:\n",
    "        for item in sen3:\n",
    "            outfile.write(\"%s\\n\" % item)\n",
    "\n",
    "# Assess inventory against AWS bucket listing\n",
    "s3 = boto3.resource('s3', aws_access_key_id=configuration['awskeyid'],\n",
    "                    aws_secret_access_key=configuration['awskeypass'])\n",
    "\n",
    "s3folderlist = []\n",
    "s3geojsonlist = []\n",
    "s3bucket = s3.Bucket(configuration['awss3bucket'])\n",
    "\n",
    "for bucket_object in s3bucket.objects.all():\n",
    "    s3bucketobject = str(bucket_object.key).split(\"/\")[2]\n",
    "    if '.SEN3' in s3bucketobject:\n",
    "        s3folderlist.append(s3bucketobject)\n",
    "    if '.FRP.geojson' in s3bucketobject:\n",
    "        s3geojsonlist.append(s3bucketobject)\n",
    "    logger.info(str(bucket_object.key).split(\"/\")[2])                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3vtgpd = pd.read_csv('s3mpc_inventory.txt')\n",
    "s3vtgpd.columns = ['title']\n",
    "# Add fields to enable monitoring\n",
    "s3vtgpd['hotspot'] = 0\n",
    "s3vtgpd['download'] = 0\n",
    "s3vtgpd['s3bucket'] = 0\n",
    "dataframelength = len(s3vtgpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if folder already downloaded and flag in gpd\n",
    "for i in range(dataframelength):\n",
    "    if s3vtgpd.loc[i]['title']+'.SEN3' in set(s3folderlist):\n",
    "        s3vtgpd.at[i, 'download'] = 1\n",
    "    if s3vtgpd.loc[i]['title']+'.FRP.geojson' in set(s3folderlist):\n",
    "        s3vtgpd.at[i, 'hotspot'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this when running all #\n",
    "# TODO - extract polygon and metadata from XML\n",
    "#for i in range(dataframelength):\n",
    "for i in range(1):\n",
    "\n",
    "    if s3vtgpd.loc[i]['download'] == 0:\n",
    "\n",
    "        filename = s3vtgpd.loc[i]['title']+'/FRP_in.nc'\n",
    "        s3hotspots = s3vtgpd.loc[i]['title'][:-5]+'.FRP.geojson'\n",
    "        if get_ftp_dir(configuration['ftpusername'], configuration['ftppassword'], configuration['ftpurl'], configuration['ftpdirectory'], s3vtgpd.loc[i]['title']) == False:\n",
    "            s3vtgpd.at[i, 'download'] = 0\n",
    "        else:\n",
    "            s3vtgpd.at[i, 'download'] = 1\n",
    "            s3hotspotsgpd = IPF_FRP_read(filename)\n",
    "            if len(s3hotspotsgpd) != 0:\n",
    "                s3hotspotsgpd.to_file(s3hotspots, driver='GeoJSON')\n",
    "                #s3vthostpotsgpdlist.append(s3hotspotsgpd)\n",
    "                s3vtgpd.at[i, 'hotspot'] = 1\n",
    "            else:\n",
    "                s3vtgpd.at[i, 'hotspot'] = 0\n",
    "\n",
    "        # Assumes AWScli configured\n",
    "        folderdate = (dt.datetime.strptime(str(s3vtgpd.loc[i]['title']).split('_')[7], \"%Y%m%dT%H%M%S\")).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        try:\n",
    "            subprocess.call(['aws', 's3', 'cp', s3vtgpd.loc[i]['title'], 's3://s3vtaustralia/data/'+folderdate+'/'+s3vtgpd.loc[i]['title'], '--recursive'])\n",
    "            subprocess.call(['aws', 's3', 'cp', s3vtgpd.loc[i]['title'][:-5]+'.FRP.geojson', 's3://s3vtaustralia/data/'+folderdate+'/'])\n",
    "        except:\n",
    "            logger.info(\"Upload failed \"+s3vtgpd.loc[i]['title'])\n",
    "        else:\n",
    "            s3vtgpd.at[i, 's3bucket'] = 1\n",
    "            subprocess.call(['rm', '-rf', s3vtgpd.loc[i]['title']])\n",
    "            #subprocess.call(['rm', '-rf', s3vtgpd.loc[i]['title']+'.zip'])\n",
    "            logger.info(\"Deleted \"+s3vtgpd.loc[i]['title'])             \n",
    "    else:\n",
    "        logger.info(s3vtgpd.loc[i]['title']+' already exists')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
